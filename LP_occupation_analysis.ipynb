{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igUHYdCsWSr3"
      },
      "outputs": [],
      "source": [
        "# Change the Demographic Name Here\n",
        "demo_name = \"SouthAfrica\"\n",
        "BASE_PATH = \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install few dependencies\n",
        "!pip install pykeen\n",
        "!pip install ampligraph"
      ],
      "metadata": {
        "id": "tu693nYKaqja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6liWJoqfWSr4"
      },
      "outputs": [],
      "source": [
        "# Import the Dependencies\n",
        "import torch\n",
        "import os\n",
        "from typing import List\n",
        "import pykeen.nn\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Feature Matrix for DistMult"
      ],
      "metadata": {
        "id": "vUuPq7LvWUR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJVuzM0PWSr4"
      },
      "outputs": [],
      "source": [
        "# Load the Distmult model -GPU is utilized\n",
        "model = torch.load(os.path.join(BASE_PATH,demo_name+ '/DistMult_Gender/trained_model.pkl'))\n",
        "entity_representation_modules: List['pykeen.nn.Representation'] = model.entity_representations\n",
        "relation_representation_modules: List['pykeen.nn.Representation'] = model.relation_representations\n",
        "entity_embeddings: pykeen.nn.Embedding = entity_representation_modules[0]\n",
        "relation_embeddings: pykeen.nn.Embedding = relation_representation_modules[0]\n",
        "entity_embedding_tensor: torch.FloatTensor = entity_embeddings()\n",
        "relation_embedding_tensor: torch.FloatTensor = relation_embeddings()\n",
        "entity_embedding_tensor: torch.FloatTensor = entity_embeddings(indices=None)\n",
        "relation_embedding_tensor: torch.FloatTensor = relation_embeddings(indices=None)\n",
        "entity_embedding_tensor = model.entity_representations[0](indices=None).cpu().detach().numpy()\n",
        "relation_embedding_tensor = model.relation_representations[0](indices=None).cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGcJ1cmzWSr4"
      },
      "outputs": [],
      "source": [
        "# load and save entity_to_id\n",
        "df = pd.read_csv(os.path.join(BASE_PATH,demo_name+ \"/DistMult_Gender/training_triples/entity_to_id.tsv\"),sep=\"\\t\",encoding='ISO-8859-1',\n",
        "                dtype={\"id\": str, \"label\": str},encoding_errors='ignore')\n",
        "entities = dict()\n",
        "for i,j in zip(df[\"id\"],df[\"label\"]):\n",
        "    try:\n",
        "        entities[j] = int(i)\n",
        "    except:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJUgN-xxWSr4"
      },
      "outputs": [],
      "source": [
        "# load and save relation_to_id\n",
        "df = pd.read_csv(os.path.join(BASE_PATH,demo_name+ \"/DistMult_Gender/training_triples/relation_to_id.tsv\"),sep=\"\\t\",encoding='ISO-8859-1')\n",
        "relation = dict()\n",
        "for i,j in zip(df[\"id\"],df[\"label\"]):\n",
        "    relation[j]=i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBPz0oC0WSr4"
      },
      "outputs": [],
      "source": [
        "# Load the feature attributes file\n",
        "df = pd.read_csv(os.path.join(BASE_PATH,demo_name+ \"/Feature_att_Gender.tsv\"),sep=\"\\t\",header=None,encoding='ISO-8859-1')\n",
        "df.columns=[\"label\",\"gender\",\"node1\",\"node2\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufM_xecxWSr4"
      },
      "outputs": [],
      "source": [
        "# Generate the feature matrix to be used for Link Prediction\n",
        "list_final=[]\n",
        "occ_emb = relation_embedding_tensor[relation[\"'occupation'\"]]\n",
        "count = 0\n",
        "c2 = 0\n",
        "for n1,n2,k,g in zip(df['node1'],df['node2'],df['label'],df['gender']):\n",
        "    try:\n",
        "        list_temp=[]\n",
        "        c2 += 1\n",
        "        node1_emb = entity_embedding_tensor[entities[n1]]\n",
        "        node2_emb = entity_embedding_tensor[entities[n2]]\n",
        "        list_temp=list(np.asarray(node1_emb))\n",
        "        list_temp.extend(np.asarray(occ_emb))\n",
        "        list_temp.extend(np.asarray(node2_emb))\n",
        "        list_temp.extend([k,g,n1,n2])\n",
        "        list_final.append(list_temp)\n",
        "    except:\n",
        "        count += 1\n",
        "df = pd.DataFrame(list_final)\n",
        "df.to_csv(os.path.join(BASE_PATH,demo_name+ \"/Features_matrix_distmult_gender.csv\"),index=False,header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Feature Matrix for TransE"
      ],
      "metadata": {
        "id": "9G2LbF-fWyGC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvTNz9J7WSr4"
      },
      "outputs": [],
      "source": [
        "## TransE embeddings - Create a Feature Matrix needs installation of ampligraph\n",
        "'''\n",
        "from ampligraph.utils import save_model,restore_model\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "model = restore_model(os.path.join(BASE_PATH,demo_name+ \"/TransE_Gender/Transe_Embeddings.pkl\"))\n",
        "df = pd.read_csv(os.path.join(BASE_PATH,demo_name+ \"/Feature_att_Gender.tsv\"),sep=\"\\t\",header=None)\n",
        "df.columns=[\"label\",\"gender\",\"node1\",\"node2\"]\n",
        "list_final=[]\n",
        "occ_emb =torch.tensor(model.get_embeddings(\"'occupation'\", embedding_type = 'relation'))\n",
        "for n1,n2,k,g in zip(df['node1'],df['node2'],df['label'],df['gender']):\n",
        "    try:\n",
        "        list_temp=[]\n",
        "        node1_emb =torch.tensor(model.get_embeddings(n1, embedding_type = 'entity'))\n",
        "        node2_emb =torch.tensor(model.get_embeddings(n2, embedding_type = 'entity'))\n",
        "        list_temp=list(np.asarray(node1_emb))\n",
        "        list_temp.extend(np.asarray(occ_emb))\n",
        "        list_temp.extend(np.asarray(node2_emb))\n",
        "        list_temp.extend([k,g,n1,n2])\n",
        "        list_final.append(list_temp)\n",
        "    except:\n",
        "        print(n1,n2,k)\n",
        "df = pd.DataFrame(list_final)\n",
        "df.to_csv(os.path.join(BASE_PATH,demo_name+ \"/Features_matrix_transe_gender.csv\"),index=False,header=None)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Classification or Link Prediction"
      ],
      "metadata": {
        "id": "0OMar9aqXcxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the filename here - either Transe/Distmult\n",
        "dataset=pd.read_csv(os.path.join(BASE_PATH,demo_name+ \"/Features_matrix_distmult_gender.csv\"),sep=\",\",header=None)\n",
        "dataset=dataset.dropna()"
      ],
      "metadata": {
        "id": "47Qh7kBGXkqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV8n1glnWSr5"
      },
      "outputs": [],
      "source": [
        "## Classification or Link Prediction\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "Y=dataset[300]\n",
        "x_train, x_test, Y_train, Y_test = train_test_split(dataset,Y, test_size=0.2,random_state=42)\n",
        "X_train  = x_train.drop([300,301,302,303],axis=1)\n",
        "X_test  = x_test.drop([300,301,302,303],axis=1)\n",
        "\n",
        "def MLP_model(learning_rates,hidden_layers,X_train, Y_train,X_test,Y_test):\n",
        "  best_score = 0\n",
        "  training_scores=[]\n",
        "  testing_scores=[]\n",
        "  for hidden_layers in Num_of_nodes_in_hiddenlayer:                               #Outer loop\n",
        "    train_scores=[]\n",
        "    test_scores=[]\n",
        "    print(\"############################################################################\")\n",
        "    print(\"The hidden layer sizes for following are \" + str(hidden_layers))\n",
        "    for l in learning_rates:                                                      #Inner Loop\n",
        "        nn_model =MLPClassifier(                                                  #Declaring the model\n",
        "                    hidden_layer_sizes=hidden_layers,                             #Specifying the hidden layers size\n",
        "                    solver='sgd',                                                 #Stochastic Gradient Descent as solver\n",
        "                    activation='tanh',  #‘identity’, ‘logistic’, ‘tanh’, ‘relu’\n",
        "                    max_iter=1500,#Keeping 1500 so as to alllow convergence\n",
        "                    random_state=42,\n",
        "                    learning_rate_init=l,  #Initializing the learning rate\n",
        "                    )\n",
        "        nn_model = nn_model.fit(X_train, Y_train)                                 #Training on the train dataset\n",
        "        if nn_model.score(X_test, Y_test) > best_score:                           #Choosing the model with best accuracy on test datset\n",
        "          best_model = nn_model\n",
        "          best_score = nn_model.score(X_test, Y_test)\n",
        "        train_scores.append(nn_model.score(X_train,Y_train))                      #Storing the train and test scores\n",
        "        test_scores.append(nn_model.score(X_test,Y_test))\n",
        "        print(\"\\tThe training accuracy of model with learning rate \" + str(l)+ \" is \" + str(nn_model.score(X_train,Y_train)))\n",
        "        print(\"\\tThe test accuracy of model with learning rate \" + str(l)+ \" is \" + str(nn_model.score(X_test,Y_test)))\n",
        "    training_scores.append(train_scores)\n",
        "    testing_scores.append(test_scores)\n",
        "  return training_scores,testing_scores,best_score,best_model\n",
        "\n",
        "\n",
        "learning_rates=[0.0001]                              #Considering 5 different learning rates\n",
        "Num_of_nodes_in_hiddenlayer=[[150,150]]                            #Considering 5 different architectures\n",
        "training_scores,testing_scores,best_score,best_model = MLP_model(learning_rates,Num_of_nodes_in_hiddenlayer,X_train, Y_train, X_test, Y_test)   #Training using different architectures\n",
        "model = best_model\n",
        "print(\"Test Accuracy\")\n",
        "print(model.score(X_test,Y_test))\n",
        "predictions = model.predict(X_test)\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(Y_test,predictions,labels=[1,0]))\n",
        "labels=[0,1]\n",
        "print(classification_report(Y_test,predictions,labels=labels))\n",
        "\n",
        "def print_results(predictions,Y_test,x_test,given_gender):\n",
        "    y_actual =[]\n",
        "    y_predicted =[]\n",
        "    for g,a,p in zip(x_test[301],Y_test,predictions):\n",
        "        if g==given_gender:\n",
        "           y_actual.append(a)\n",
        "           y_predicted.append(p)\n",
        "#     m = confusion_matrix(y_actual,y_predicted).ravel()\n",
        "    TP=0\n",
        "    TN=0\n",
        "    FP=0\n",
        "    FN=0\n",
        "    for i,j in zip(y_actual,y_predicted):\n",
        "        if j==i and j==1:\n",
        "            TP+=1\n",
        "        elif j==i and j==0:\n",
        "            TN+=1\n",
        "        elif j!=i and i==1:\n",
        "            FN+=1\n",
        "        elif j!=i and i==0:\n",
        "            FP+=1\n",
        "    print(TN,FP,FN,TP)\n",
        "    #print(classification_report(y_actual,y_predicted,labels=labels))\n",
        "    return TN,FP,FN,TP\n",
        "print(\"------------------Male Details--------------------\")\n",
        "TN, FP, FN, TP = print_results(predictions,Y_test,x_test,\"male\")\n",
        "N = TP+FP+FN+TN #Total population\n",
        "TPR = TP/(TP+FN) # True positive rate\n",
        "FPR = FP/(FP+TN) # False positive rate\n",
        "FNR = FN/(TP+FN) # False negative rate\n",
        "PPP = (TP + FP)/N # % predicted as positive\n",
        "print(round(TPR,2),round(FPR,2),round(FNR,2),round(PPP,2))\n",
        "print(\"------------------Female Details--------------------\")\n",
        "TN, FP, FN, TP = print_results(predictions,Y_test,x_test,\"female\")\n",
        "N = TP+FP+FN+TN #Total population\n",
        "TPR = TP/(TP+FN) # True positive rate\n",
        "FPR = FP/(FP+TN) # False positive rate\n",
        "FNR = FN/(TP+FN) # False negative rate\n",
        "PPP = (TP + FP)/N # % predicted as positive\n",
        "print(round(TPR,2),round(FPR,2),round(FNR,2),round(PPP,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBtnO04JWSr5"
      },
      "outputs": [],
      "source": [
        "def print_results_occupation(predictions,Y_test,x_test,given_occupation,given_gender):\n",
        "    y_actual =[]\n",
        "    y_predicted =[]\n",
        "    for g,a,p,o in zip(x_test[301],Y_test,predictions,x_test[303]):\n",
        "        if g==given_gender and o==given_occupation:\n",
        "           y_actual.append(a)\n",
        "           y_predicted.append(p)\n",
        "    TP=0\n",
        "    TN=0\n",
        "    FP=0\n",
        "    FN=0\n",
        "    for i,j in zip(y_actual,y_predicted):\n",
        "        if j==i and j==1:\n",
        "            TP+=1\n",
        "        elif j==i and j==0:\n",
        "            TN+=1\n",
        "        elif j!=i and i==1:\n",
        "            FN+=1\n",
        "        elif j!=i and i==0:\n",
        "            FP+=1\n",
        "    N=TP+TN+FP+FN\n",
        "\n",
        "    TPR = 0 if TP==0 else TP/(TP+FN)\n",
        "    FPR = 0 if FP==0 else FP/(FP+TN)\n",
        "    FNR = 0 if FN==0 else FN/(TP+FN)\n",
        "\n",
        "    return TPR,FPR,FNR,N\n",
        "\n",
        "list_final = []\n",
        "for occ in set(x_test[303]):\n",
        "    TPR_m,FPR_m,FNR_m,N1 = print_results_occupation(predictions,Y_test,x_test,occ,\"male\")\n",
        "    TPR_f,FPR_f,FNR_f,N2 = print_results_occupation(predictions,Y_test,x_test,occ,\"female\")\n",
        "    list_final.append([occ,N1,N2,round(TPR_m,2),round(FPR_m,2),round(FNR_m,2),round(TPR_f,2),round(FPR_f,2),round(FNR_f,2)])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the filename here\n",
        "df= pd.DataFrame(list_final)\n",
        "df.to_csv(os.path.join(BASE_PATH,demo_name+ \"/Occupation_biased_distmult_gender.tsv\"),sep=\"\\t\",header=None,index=False)"
      ],
      "metadata": {
        "id": "3wGP4mS6X6Z1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pykeen-ksk",
      "language": "python",
      "name": "pykeen-ksk"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}